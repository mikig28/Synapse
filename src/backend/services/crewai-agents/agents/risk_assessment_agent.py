"""
Risk Assessment Agent for Ultra-Thinking Analysis
Provides comprehensive risk analysis, pattern recognition, and threat assessment with early warning capabilities.
"""

import json
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import re
from enum import Enum
import math

logger = logging.getLogger(__name__)

class RiskCategory(Enum):
    OPERATIONAL = "operational"
    FINANCIAL = "financial"
    STRATEGIC = "strategic"
    REGULATORY = "regulatory"
    TECHNOLOGICAL = "technological"
    REPUTATIONAL = "reputational"
    MARKET = "market"
    CYBER_SECURITY = "cyber_security"
    SUPPLY_CHAIN = "supply_chain"
    ENVIRONMENTAL = "environmental"

class RiskSeverity(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MODERATE = "moderate"
    LOW = "low"
    MINIMAL = "minimal"

class RiskLikelihood(Enum):
    VERY_HIGH = "very_high"  # >80%
    HIGH = "high"           # 60-80%
    MODERATE = "moderate"    # 40-60%
    LOW = "low"             # 20-40%
    VERY_LOW = "very_low"   # <20%

class ThreatVector(Enum):
    INTERNAL = "internal"
    EXTERNAL = "external"
    SYSTEMIC = "systemic"
    CASCADING = "cascading"

@dataclass
class RiskIndicator:
    """Individual risk indicator with pattern recognition"""
    name: str
    category: RiskCategory
    description: str
    severity: RiskSeverity
    likelihood: RiskLikelihood
    threat_vector: ThreatVector
    early_warning_signals: List[str]
    leading_indicators: List[str]
    lagging_indicators: List[str]
    mitigation_strategies: List[str]
    interdependencies: List[str]
    historical_precedents: List[str]
    confidence_score: float
    trend_direction: str  # "increasing", "decreasing", "stable"
    velocity: float  # Rate of change

@dataclass
class RiskCluster:
    """Related risks that could compound or cascade"""
    name: str
    constituent_risks: List[str]
    cluster_type: str  # "causal", "correlational", "systemic"
    amplification_factor: float
    cascade_probability: float
    compound_severity: RiskSeverity
    intervention_points: List[str]
    monitoring_priorities: List[str]
    confidence_score: float

@dataclass
class RiskScenario:
    """Comprehensive risk scenario with multiple risk interactions"""
    name: str
    description: str
    trigger_events: List[str]
    risk_chain: List[str]
    probability: float
    impact_magnitude: float
    time_horizon: str
    affected_domains: List[str]
    critical_path: List[str]
    prevention_strategies: List[str]
    contingency_plans: List[str]
    confidence_score: float

@dataclass
class EarlyWarningSystem:
    """Proactive risk monitoring and alert system"""
    warning_signals: List[Dict[str, Any]]
    risk_thresholds: Dict[str, float]
    monitoring_frequency: str
    alert_priorities: List[str]
    escalation_procedures: List[str]
    response_protocols: Dict[str, List[str]]
    signal_reliability: Dict[str, float]
    false_positive_rate: float

@dataclass
class RiskAssessment:
    """Complete risk assessment report with ultra-thinking analysis"""
    risk_indicators: List[RiskIndicator]
    risk_clusters: List[RiskCluster]
    risk_scenarios: List[RiskScenario]
    early_warning_system: EarlyWarningSystem
    risk_matrix: Dict[str, Any]
    mitigation_portfolio: Dict[str, Any]
    monitoring_dashboard: Dict[str, Any]
    strategic_recommendations: List[str]
    confidence_score: float
    analysis_timestamp: str

class RiskAssessmentAgent:
    """
    Advanced Risk Assessment Agent for ultra-thinking analysis.
    
    Provides comprehensive risk analysis, pattern recognition, threat assessment,
    and early warning capabilities using multi-step reasoning chains.
    """
    
    def __init__(self):
        self.agent_name = "Risk Assessment Agent"
        self.version = "2.0.0"
        self.capabilities = [
            "pattern_recognition",
            "threat_analysis",
            "risk_quantification",
            "early_warning_generation",
            "scenario_planning",
            "risk_correlation_analysis",
            "mitigation_strategy_development",
            "monitoring_system_design"
        ]
        
        # Risk analysis frameworks
        self.analysis_frameworks = {
            "bow_tie_analysis": self._perform_bow_tie_analysis,
            "fault_tree_analysis": self._perform_fault_tree_analysis,
            "monte_carlo_simulation": self._perform_monte_carlo_risk,
            "scenario_stress_testing": self._perform_scenario_stress_test,
            "cascade_analysis": self._perform_cascade_analysis
        }
        
        # Risk pattern libraries
        self.risk_patterns = {
            "financial_stress_signals": [
                "liquidity crunch", "credit rating downgrade", "debt covenant breach",
                "cash flow negative", "funding gap", "margin compression", "bad debt spike"
            ],
            "operational_failure_patterns": [
                "system outage", "supply chain disruption", "quality failure",
                "regulatory violation", "safety incident", "production bottleneck"
            ],
            "market_volatility_indicators": [
                "price volatility", "demand fluctuation", "competitive pressure",
                "market share loss", "customer churn", "pricing pressure"
            ],
            "technological_disruption_signals": [
                "obsolescence risk", "security breach", "platform migration",
                "technology shift", "digital transformation", "automation threat"
            ],
            "regulatory_change_indicators": [
                "policy change", "compliance requirement", "regulatory investigation",
                "legal challenge", "industry standard", "environmental regulation"
            ],
            "reputational_risk_factors": [
                "negative publicity", "social media backlash", "stakeholder criticism",
                "brand damage", "trust erosion", "public relations crisis"
            ]
        }
        
        # Risk interdependency mapping
        self.risk_interdependencies = {
            RiskCategory.FINANCIAL: [RiskCategory.OPERATIONAL, RiskCategory.MARKET, RiskCategory.STRATEGIC],
            RiskCategory.OPERATIONAL: [RiskCategory.FINANCIAL, RiskCategory.SUPPLY_CHAIN, RiskCategory.TECHNOLOGICAL],
            RiskCategory.TECHNOLOGICAL: [RiskCategory.CYBER_SECURITY, RiskCategory.OPERATIONAL, RiskCategory.STRATEGIC],
            RiskCategory.REGULATORY: [RiskCategory.FINANCIAL, RiskCategory.OPERATIONAL, RiskCategory.REPUTATIONAL],
            RiskCategory.REPUTATIONAL: [RiskCategory.MARKET, RiskCategory.FINANCIAL, RiskCategory.REGULATORY]
        }

    def ultra_assess_risks(
        self, 
        content: Dict[str, Any], 
        topics: List[str],
        domain_context: Optional[str] = None
    ) -> RiskAssessment:
        """
        Ultra-thinking risk assessment with multi-step reasoning chains.
        
        7-Phase Ultra-Assessment Process:
        1. Risk Pattern Recognition & Classification
        2. Risk Quantification & Scoring
        3. Risk Clustering & Correlation Analysis
        4. Scenario Development & Stress Testing
        5. Early Warning System Design
        6. Mitigation Strategy Development
        7. Risk Intelligence Synthesis
        """
        logger.info(f"{self.agent_name}: Starting ultra-risk assessment for topics: {topics}")
        
        try:
            # Phase 1: Risk Pattern Recognition & Classification
            risk_indicators = self._recognize_and_classify_risks(content, topics, domain_context)
            
            # Phase 2: Risk Quantification & Scoring
            quantified_risks = self._quantify_and_score_risks(risk_indicators, content)
            
            # Phase 3: Risk Clustering & Correlation Analysis
            risk_clusters = self._analyze_risk_clusters(quantified_risks, content)
            
            # Phase 4: Scenario Development & Stress Testing
            risk_scenarios = self._develop_risk_scenarios(quantified_risks, risk_clusters, content)
            
            # Phase 5: Early Warning System Design
            early_warning_system = self._design_early_warning_system(quantified_risks, risk_scenarios)
            
            # Phase 6: Mitigation Strategy Development
            mitigation_portfolio = self._develop_mitigation_strategies(quantified_risks, risk_clusters, risk_scenarios)
            
            # Phase 7: Risk Intelligence Synthesis
            risk_matrix = self._create_risk_matrix(quantified_risks, risk_clusters)
            monitoring_dashboard = self._design_monitoring_dashboard(quantified_risks, early_warning_system)
            strategic_recommendations = self._generate_risk_recommendations(
                quantified_risks, risk_clusters, risk_scenarios, mitigation_portfolio
            )
            
            # Calculate overall confidence score
            confidence_score = self._calculate_assessment_confidence(
                quantified_risks, risk_clusters, risk_scenarios
            )
            
            risk_assessment = RiskAssessment(
                risk_indicators=quantified_risks,
                risk_clusters=risk_clusters,
                risk_scenarios=risk_scenarios,
                early_warning_system=early_warning_system,
                risk_matrix=risk_matrix,
                mitigation_portfolio=mitigation_portfolio,
                monitoring_dashboard=monitoring_dashboard,
                strategic_recommendations=strategic_recommendations,
                confidence_score=confidence_score,
                analysis_timestamp=datetime.now().isoformat()
            )
            
            logger.info(f"{self.agent_name}: Ultra-assessment completed with {confidence_score:.1%} confidence")
            return risk_assessment
            
        except Exception as e:
            logger.error(f"{self.agent_name}: Ultra-assessment failed: {str(e)}")
            return self._create_fallback_assessment()

    def _recognize_and_classify_risks(
        self, 
        content: Dict[str, Any], 
        topics: List[str],
        domain_context: Optional[str]
    ) -> List[RiskIndicator]:
        """Phase 1: Advanced risk pattern recognition and classification"""
        logger.info(f"{self.agent_name}: Recognizing and classifying risks")
        
        risk_indicators = []
        content_text = self._extract_text_from_content(content)
        
        # Pattern-based risk detection
        for category, patterns in self.risk_patterns.items():
            detected_risks = self._detect_risk_patterns(content_text, patterns, category)
            risk_indicators.extend(detected_risks)
        
        # Contextual risk analysis
        contextual_risks = self._analyze_contextual_risks(content, topics, domain_context)
        risk_indicators.extend(contextual_risks)
        
        # Emerging risk identification
        emerging_risks = self._identify_emerging_risks(content_text, topics)
        risk_indicators.extend(emerging_risks)
        
        # Cross-reference and validate risks
        validated_risks = self._validate_risk_indicators(risk_indicators, content)
        
        return validated_risks

    def _detect_risk_patterns(
        self, 
        content_text: str, 
        patterns: List[str], 
        category: str
    ) -> List[RiskIndicator]:
        """Detect specific risk patterns in content"""
        
        detected_risks = []
        
        for pattern in patterns:
            if pattern.lower() in content_text.lower():
                # Extract context around the pattern
                risk_context = self._extract_risk_context(content_text, pattern)
                
                # Create risk indicator
                risk_indicator = self._create_risk_indicator_from_pattern(
                    pattern, category, risk_context
                )
                
                if risk_indicator:
                    detected_risks.append(risk_indicator)
        
        return detected_risks

    def _create_risk_indicator_from_pattern(
        self, 
        pattern: str, 
        category: str, 
        context: str
    ) -> Optional[RiskIndicator]:
        """Create structured risk indicator from detected pattern"""
        
        # Map category string to enum
        risk_category = self._map_risk_category(category)
        
        # Assess severity based on context
        severity = self._assess_pattern_severity(pattern, context)
        
        # Assess likelihood based on context
        likelihood = self._assess_pattern_likelihood(pattern, context)
        
        # Determine threat vector
        threat_vector = self._determine_threat_vector(pattern, context)
        
        # Generate mitigation strategies
        mitigation_strategies = self._generate_pattern_mitigations(pattern, category)
        
        # Identify early warning signals
        early_warning_signals = self._identify_early_warning_signals(pattern, category)
        
        # Calculate confidence score
        confidence_score = self._calculate_pattern_confidence(pattern, context)
        
        return RiskIndicator(
            name=pattern.replace("_", " ").title(),
            category=risk_category,
            description=f"Risk indicator detected: {pattern} in {category} domain",
            severity=severity,
            likelihood=likelihood,
            threat_vector=threat_vector,
            early_warning_signals=early_warning_signals,
            leading_indicators=[f"{pattern} frequency increase", f"{category} domain instability"],
            lagging_indicators=[f"{pattern} impact materialization", f"{category} performance degradation"],
            mitigation_strategies=mitigation_strategies,
            interdependencies=self._identify_risk_interdependencies(risk_category),
            historical_precedents=[f"Historical {pattern} events in {category}"],
            confidence_score=confidence_score,
            trend_direction=self._assess_trend_direction(pattern, context),
            velocity=self._calculate_risk_velocity(pattern, context)
        )

    def _quantify_and_score_risks(
        self, 
        risk_indicators: List[RiskIndicator], 
        content: Dict[str, Any]
    ) -> List[RiskIndicator]:
        """Phase 2: Quantify and score risks using advanced metrics"""
        logger.info(f"{self.agent_name}: Quantifying and scoring risks")
        
        quantified_risks = []
        
        for risk in risk_indicators:
            # Enhanced risk scoring
            quantified_risk = self._enhance_risk_scoring(risk, content)
            quantified_risks.append(quantified_risk)
        
        # Sort by risk score (severity Ã— likelihood Ã— velocity)
        quantified_risks.sort(
            key=lambda r: self._calculate_composite_risk_score(r),
            reverse=True
        )
        
        return quantified_risks

    def _analyze_risk_clusters(
        self, 
        risk_indicators: List[RiskIndicator], 
        content: Dict[str, Any]
    ) -> List[RiskCluster]:
        """Phase 3: Analyze risk correlations and clustering"""
        logger.info(f"{self.agent_name}: Analyzing risk clusters")
        
        risk_clusters = []
        
        # Group risks by category
        category_clusters = self._create_category_clusters(risk_indicators)
        risk_clusters.extend(category_clusters)
        
        # Identify causal relationships
        causal_clusters = self._identify_causal_clusters(risk_indicators)
        risk_clusters.extend(causal_clusters)
        
        # Find systemic risk patterns
        systemic_clusters = self._identify_systemic_clusters(risk_indicators)
        risk_clusters.extend(systemic_clusters)
        
        return risk_clusters

    def _develop_risk_scenarios(
        self, 
        risk_indicators: List[RiskIndicator], 
        risk_clusters: List[RiskCluster],
        content: Dict[str, Any]
    ) -> List[RiskScenario]:
        """Phase 4: Develop comprehensive risk scenarios"""
        logger.info(f"{self.agent_name}: Developing risk scenarios")
        
        scenarios = []
        
        # High-probability scenarios
        high_prob_scenarios = self._create_high_probability_scenarios(risk_indicators)
        scenarios.extend(high_prob_scenarios)
        
        # High-impact scenarios
        high_impact_scenarios = self._create_high_impact_scenarios(risk_indicators, risk_clusters)
        scenarios.extend(high_impact_scenarios)
        
        # Black swan scenarios
        black_swan_scenarios = self._create_black_swan_scenarios(risk_indicators)
        scenarios.extend(black_swan_scenarios)
        
        return scenarios[:10]  # Return top 10 scenarios

    def _design_early_warning_system(
        self, 
        risk_indicators: List[RiskIndicator], 
        risk_scenarios: List[RiskScenario]
    ) -> EarlyWarningSystem:
        """Phase 5: Design comprehensive early warning system"""
        logger.info(f"{self.agent_name}: Designing early warning system")
        
        # Aggregate all warning signals
        warning_signals = []
        for risk in risk_indicators:
            for signal in risk.early_warning_signals:
                warning_signals.append({
                    "signal": signal,
                    "risk_category": risk.category.value,
                    "severity": risk.severity.value,
                    "confidence": risk.confidence_score
                })
        
        # Set risk thresholds
        risk_thresholds = self._calculate_risk_thresholds(risk_indicators)
        
        # Design response protocols
        response_protocols = self._design_response_protocols(risk_indicators, risk_scenarios)
        
        return EarlyWarningSystem(
            warning_signals=warning_signals,
            risk_thresholds=risk_thresholds,
            monitoring_frequency="continuous",
            alert_priorities=self._prioritize_alerts(risk_indicators),
            escalation_procedures=self._design_escalation_procedures(risk_indicators),
            response_protocols=response_protocols,
            signal_reliability=self._assess_signal_reliability(warning_signals),
            false_positive_rate=0.15  # Estimated 15% false positive rate
        )

    def _generate_risk_recommendations(
        self,
        risk_indicators: List[RiskIndicator],
        risk_clusters: List[RiskCluster],
        risk_scenarios: List[RiskScenario],
        mitigation_portfolio: Dict[str, Any]
    ) -> List[str]:
        """Generate strategic risk management recommendations"""
        
        recommendations = []
        
        # Critical risk recommendations
        critical_risks = [r for r in risk_indicators if r.severity == RiskSeverity.CRITICAL]
        if critical_risks:
            recommendations.append(
                f"ðŸš¨ **Immediate Action Required**: Address {len(critical_risks)} critical risks including {critical_risks[0].name} through emergency response protocols"
            )
        
        # High-velocity risk recommendations
        high_velocity_risks = [r for r in risk_indicators if r.velocity > 0.7]
        if high_velocity_risks:
            recommendations.append(
                f"âš¡ **Rapid Response**: Monitor fast-moving risks ({', '.join([r.name for r in high_velocity_risks[:3]])}) with increased frequency"
            )
        
        # Risk cluster recommendations
        high_impact_clusters = [c for c in risk_clusters if c.compound_severity == RiskSeverity.CRITICAL]
        if high_impact_clusters:
            recommendations.append(
                f"ðŸ”— **Systemic Risk Management**: Address interconnected risk clusters to prevent cascade effects in {high_impact_clusters[0].name}"
            )
        
        # Early warning recommendations
        recommendations.append(
            "ðŸ“Š **Early Warning Implementation**: Deploy continuous monitoring for leading risk indicators to enable proactive intervention"
        )
        
        # Scenario planning recommendations
        high_prob_scenarios = [s for s in risk_scenarios if s.probability > 0.6]
        if high_prob_scenarios:
            recommendations.append(
                f"ðŸ“‹ **Scenario Preparedness**: Develop contingency plans for high-probability scenarios: {high_prob_scenarios[0].name}"
            )
        
        # Portfolio diversification recommendations
        recommendations.append(
            "ðŸ›¡ï¸ **Risk Diversification**: Implement portfolio approach to risk mitigation across multiple categories and time horizons"
        )
        
        return recommendations

    # Helper methods for risk analysis
    def _extract_text_from_content(self, content: Dict[str, Any]) -> str:
        """Extract text content for risk pattern analysis"""
        text_parts = []
        
        if isinstance(content, dict):
            for key, value in content.items():
                if isinstance(value, str):
                    text_parts.append(value)
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, str):
                            text_parts.append(item)
                        elif isinstance(item, dict) and 'content' in item:
                            text_parts.append(str(item['content']))
        
        return " ".join(text_parts)

    def _map_risk_category(self, category_str: str) -> RiskCategory:
        """Map category string to RiskCategory enum"""
        category_mapping = {
            "financial_stress_signals": RiskCategory.FINANCIAL,
            "operational_failure_patterns": RiskCategory.OPERATIONAL,
            "market_volatility_indicators": RiskCategory.MARKET,
            "technological_disruption_signals": RiskCategory.TECHNOLOGICAL,
            "regulatory_change_indicators": RiskCategory.REGULATORY,
            "reputational_risk_factors": RiskCategory.REPUTATIONAL
        }
        return category_mapping.get(category_str, RiskCategory.OPERATIONAL)

    def _assess_pattern_severity(self, pattern: str, context: str) -> RiskSeverity:
        """Assess risk severity based on pattern and context"""
        high_severity_keywords = ["critical", "severe", "major", "crisis", "emergency"]
        moderate_severity_keywords = ["significant", "important", "notable", "concern"]
        
        context_lower = context.lower()
        
        if any(keyword in context_lower for keyword in high_severity_keywords):
            return RiskSeverity.HIGH
        elif any(keyword in context_lower for keyword in moderate_severity_keywords):
            return RiskSeverity.MODERATE
        else:
            return RiskSeverity.LOW

    def _calculate_composite_risk_score(self, risk: RiskIndicator) -> float:
        """Calculate composite risk score"""
        severity_weight = {
            RiskSeverity.CRITICAL: 1.0,
            RiskSeverity.HIGH: 0.8,
            RiskSeverity.MODERATE: 0.6,
            RiskSeverity.LOW: 0.4,
            RiskSeverity.MINIMAL: 0.2
        }
        
        likelihood_weight = {
            RiskLikelihood.VERY_HIGH: 1.0,
            RiskLikelihood.HIGH: 0.8,
            RiskLikelihood.MODERATE: 0.6,
            RiskLikelihood.LOW: 0.4,
            RiskLikelihood.VERY_LOW: 0.2
        }
        
        severity_score = severity_weight.get(risk.severity, 0.5)
        likelihood_score = likelihood_weight.get(risk.likelihood, 0.5)
        velocity_score = min(risk.velocity, 1.0)
        confidence_adjustment = risk.confidence_score
        
        composite_score = (severity_score * likelihood_score * (1 + velocity_score)) * confidence_adjustment
        return composite_score

    def _create_fallback_assessment(self) -> RiskAssessment:
        """Create fallback risk assessment when analysis fails"""
        return RiskAssessment(
            risk_indicators=[],
            risk_clusters=[],
            risk_scenarios=[],
            early_warning_system=EarlyWarningSystem(
                warning_signals=[],
                risk_thresholds={},
                monitoring_frequency="daily",
                alert_priorities=[],
                escalation_procedures=[],
                response_protocols={},
                signal_reliability={},
                false_positive_rate=0.2
            ),
            risk_matrix={"status": "Analysis requires additional data"},
            mitigation_portfolio={"status": "Mitigation strategies pending risk identification"},
            monitoring_dashboard={"status": "Dashboard configuration in progress"},
            strategic_recommendations=[
                "ðŸ“Š **Data Enhancement**: Increase data collection for comprehensive risk assessment",
                "ðŸ” **Risk Monitoring**: Implement baseline risk monitoring for pattern recognition"
            ],
            confidence_score=0.3,
            analysis_timestamp=datetime.now().isoformat()
        )

    # Additional placeholder implementations for comprehensive risk analysis
    def _extract_risk_context(self, content_text: str, pattern: str) -> str:
        """Extract context around risk pattern"""
        pattern_index = content_text.lower().find(pattern.lower())
        if pattern_index == -1:
            return ""
        
        # Extract 100 characters before and after the pattern
        start = max(0, pattern_index - 100)
        end = min(len(content_text), pattern_index + len(pattern) + 100)
        return content_text[start:end]

    def _assess_pattern_likelihood(self, pattern: str, context: str) -> RiskLikelihood:
        """Assess risk likelihood based on pattern and context"""
        high_likelihood_keywords = ["imminent", "likely", "probable", "expected"]
        moderate_likelihood_keywords = ["possible", "potential", "may", "could"]
        
        context_lower = context.lower()
        
        if any(keyword in context_lower for keyword in high_likelihood_keywords):
            return RiskLikelihood.HIGH
        elif any(keyword in context_lower for keyword in moderate_likelihood_keywords):
            return RiskLikelihood.MODERATE
        else:
            return RiskLikelihood.LOW

    def export_risk_assessment(self, assessment: RiskAssessment) -> Dict[str, Any]:
        """Export risk assessment in structured format"""
        return {
            "risk_assessment": asdict(assessment),
            "export_metadata": {
                "agent": self.agent_name,
                "version": self.version,
                "export_timestamp": datetime.now().isoformat(),
                "assessment_confidence": assessment.confidence_score
            }
        }